{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80f8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da2049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/3113588624.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Schlüssel'] = df['Schlüssel'].astype(int)\n",
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/3113588624.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Schlüssel'] = df['Schlüssel'].astype(int)\n",
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/3113588624.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Schlüssel'] = df['Schlüssel'].astype(int)\n",
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/3113588624.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Schlüssel'] = df['Schlüssel'].astype(int)\n",
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/3113588624.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Schlüssel'] = df['Schlüssel'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "def load_and_clean_data(file_path):\n",
    "    df = pd.read_excel(file_path).iloc[3:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def filter_data(df):\n",
    "    excluded_keys = ['------', '892000', '892500', '734600']\n",
    "    df = df[~df['Schlüssel'].isin(excluded_keys)]\n",
    "    df['Schlüssel'] = df['Schlüssel'].astype(int)\n",
    "    return df\n",
    "\n",
    "def categorize_crimes(df):\n",
    "    crime_conditions = [\n",
    "        (df['Schlüssel'] >= 10000) & (df['Schlüssel'] < 20000),\n",
    "        (df['Schlüssel'] >= 20000) & (df['Schlüssel'] <= 30000),\n",
    "        (df['Schlüssel'] >= 110000) & (df['Schlüssel'] <= 145000),\n",
    "        (df['Schlüssel'] >= 210000) & (df['Schlüssel'] <= 219050),\n",
    "        ((df['Schlüssel'] >= 220000) & (df['Schlüssel'] <= 225000)) | (df['Schlüssel'] == 655100),\n",
    "        (df['Schlüssel'] >= 230000) & (df['Schlüssel'] <= 239540),\n",
    "        (df['Schlüssel'] >= 621100) & (df['Schlüssel'] <= 621120),\n",
    "        (df['Schlüssel'] >= 641000) & (df['Schlüssel'] <= 641040),\n",
    "        (df['Schlüssel'] == 670021),\n",
    "        (df['Schlüssel'] >= 725400) & (df['Schlüssel'] <= 725410)\n",
    "    ]\n",
    "    \n",
    "    crime_labels = [\n",
    "        'Murder', 'Homicide', 'Sex-Related Offenses', 'Robbery', 'Assault',\n",
    "        'Deprivation of Personal Liberty', 'Resisting Arrest', 'Arson', \n",
    "        'Abandonment', 'Smuggling of Persons'\n",
    "    ]\n",
    "    \n",
    "    df['Crime'] = np.select(crime_conditions, crime_labels, default='Other')\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, total_deutschland, total_nichtdeutsche):\n",
    "    df = df[df['Fall-status'] == 'insg.']\n",
    "    df = df.drop(columns=['Schlüssel', 'Straftat', 'Fall-status'])\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if column != 'Crime':\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce').fillna(0)\n",
    "    \n",
    "    df_gr = df.groupby('Crime').sum()\n",
    "    df_gr = df_gr.loc[:, (df_gr != 0).any(axis=0)]\n",
    "    df_gr = df_gr.loc[(df_gr != 0).any(axis=1)]\n",
    "    \n",
    "    df_gr['Deutsche_Opfer_norm'] = df_gr['Deutschland'] / total_deutschland\n",
    "    df_gr['Nichtdeutsche_Opfer_norm'] = df_gr['Nichtdeutsche insgesamt'] / total_nichtdeutsche\n",
    "    \n",
    "    return df_gr\n",
    "\n",
    "def process_data(file_path, year, total_deutschland, total_nichtdeutsche):\n",
    "    df = load_and_clean_data(file_path)\n",
    "    df = filter_data(df)\n",
    "    df = categorize_crimes(df)\n",
    "    df_gr = preprocess_data(df, total_deutschland, total_nichtdeutsche)\n",
    "    df_gr = df_gr.rename(columns=lambda x: f\"{x}_{year}\")\n",
    "    return df_gr\n",
    "\n",
    "data_files = {\n",
    "    2023: ('BU-O-04-T911-O-Staatsangehoerigkeiten_xls_2023.xlsx', 71855657, 12751359),\n",
    "    2022: ('BU-O-04-T911-O-Staatsangehoerigkeiten_xls_2022.xlsx', 72034650, 12324195),\n",
    "    2021: ('BU-O-04-T911-O-Staatsangehoerigkeiten_xls_2021.xlsx', 72344071, 10893053),\n",
    "    2020: ('BU-O-04-T911-O-Staatsangehoerigkeiten_xls_2020.xlsx', 72569978, 10585053),\n",
    "    2019: ('BU-O-04-T911-O-Staatsangehoerigkeiten_xls_2019.xlsx', 72768689, 10398022)\n",
    "}\n",
    "\n",
    "data_gr_dict = {year: process_data(file_path, year, total_deutschland, total_nichtdeutsche) \n",
    "                for year, (file_path, total_deutschland, total_nichtdeutsche) in data_files.items()}\n",
    "\n",
    "data_combined = pd.concat(data_gr_dict.values(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ee9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame for population data\n",
    "data_population = pd.DataFrame({\n",
    "    'Jahr': ['2019', '2020', '2021', '2022', '2023'],\n",
    "    'Deutsche_total': [None] * 5,\n",
    "    'Nichtdeutsche_total': [None] * 5\n",
    "})\n",
    "\n",
    "# Populate the DataFrame using a loop\n",
    "for year, (file_path, deutsche_total, nichtdeutsche_total) in data_files.items():\n",
    "    data_population.loc[data_population['Jahr'] == str(year), 'Deutsche_total'] = deutsche_total\n",
    "    data_population.loc[data_population['Jahr'] == str(year), 'Nichtdeutsche_total'] = nichtdeutsche_total\n",
    "\n",
    "# Fill NaN values with 0 in the combined data\n",
    "data_combined = data_combined.fillna(0)\n",
    "\n",
    "# Select columns for the CSV output\n",
    "columns_to_export = [\n",
    "    'Deutsche_Opfer_norm_2019', 'Nichtdeutsche_Opfer_norm_2019',\n",
    "    'Deutsche_Opfer_norm_2020', 'Nichtdeutsche_Opfer_norm_2020',\n",
    "    'Deutsche_Opfer_norm_2021', 'Nichtdeutsche_Opfer_norm_2021',\n",
    "    'Deutsche_Opfer_norm_2022', 'Nichtdeutsche_Opfer_norm_2022',\n",
    "    'Deutsche_Opfer_norm_2023', 'Nichtdeutsche_Opfer_norm_2023'\n",
    "]\n",
    "\n",
    "# Save the selected columns to a CSV file\n",
    "data_combined[columns_to_export].to_csv('data_D_NichtD_proportion.csv')\n",
    "\n",
    "# Save the population data to a CSV file\n",
    "data_population.to_csv('data_D_NichtD_population.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897d230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/3848557408.py:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_melted['Category'] = df_melted['Year_Variable'].str.replace(r'_\\d{4}$', '')\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to save\n",
    "columns_to_save = [\n",
    "    'Deutsche_Opfer_norm_2019', 'Nichtdeutsche_Opfer_norm_2019',\n",
    "    'Deutsche_Opfer_norm_2020', 'Nichtdeutsche_Opfer_norm_2020',\n",
    "    'Deutsche_Opfer_norm_2021', 'Nichtdeutsche_Opfer_norm_2021',\n",
    "    'Deutsche_Opfer_norm_2022', 'Nichtdeutsche_Opfer_norm_2022',\n",
    "    'Deutsche_Opfer_norm_2023', 'Nichtdeutsche_Opfer_norm_2023'\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with only the specified columns\n",
    "df_to_pivot = data_combined[columns_to_save]\n",
    "\n",
    "# Use pd.melt to pivot the DataFrame\n",
    "df_melted = pd.melt(df_to_pivot.reset_index(), id_vars='Crime', value_vars=columns_to_save,\n",
    "                    var_name='Year_Variable', value_name='Value')\n",
    "\n",
    "# Extract the year and the category from the 'Year_Variable' column\n",
    "df_melted['Year'] = df_melted['Year_Variable'].str.extract(r'(\\d{4})$')\n",
    "df_melted['Category'] = df_melted['Year_Variable'].str.replace(r'_\\d{4}$', '')\n",
    "\n",
    "# Rename categories for clarity\n",
    "df_melted['Category'] = df_melted['Category'].replace({\n",
    "    'Deutsche_Opfer_norm': 'Deutsche Opfer der Gewalt',\n",
    "    'Nichtdeutsche_Opfer_norm': 'Nichtdeutsche Opfer der Gewalt'\n",
    "})\n",
    "\n",
    "# Remove the 'Year_Variable' column\n",
    "df_melted = df_melted.drop(columns=['Year_Variable'])\n",
    "\n",
    "# Rearrange the columns for better readability\n",
    "df_melted = df_melted[['Crime', 'Year', 'Category', 'Value']]\n",
    "\n",
    "# Save the tidy DataFrame to a CSV file\n",
    "df_melted.to_csv('data_tidy.csv', index=False)\n",
    "\n",
    "# Create a pivot table with 'Year' and 'Crime' as the index and 'Category' as the columns\n",
    "df_pivoted_back = df_melted.pivot_table(index=['Year', 'Crime'], columns='Category', values='Value')\n",
    "\n",
    "# Reset the index to make 'Year' and 'Crime' columns again\n",
    "df_pivoted_back = df_pivoted_back.reset_index()\n",
    "\n",
    "# Save the pivoted DataFrame to a CSV file\n",
    "df_pivoted_back.to_csv('data_pivoted_back.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e85123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/81259306.py:17: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_normalized = df_pivoted_back.groupby('Crime').apply(\n"
     ]
    }
   ],
   "source": [
    "# Function to normalize data within each group for combined columns\n",
    "def combined_min_max_normalize(group, columns):\n",
    "    combined_min = group[columns].min().min()\n",
    "    combined_max = group[columns].max().max()\n",
    "    result = group.copy()\n",
    "    for column in columns:\n",
    "        result[column] = (group[column] - combined_min) / (combined_max - combined_min)\n",
    "    return result\n",
    "\n",
    "# Fill NaN values with 0 in the pivoted DataFrame\n",
    "df_pivoted_back = df_pivoted_back.fillna(0)\n",
    "\n",
    "# Define columns to normalize together\n",
    "columns_to_normalize = ['Deutsche Opfer der Gewalt', 'Nichtdeutsche Opfer der Gewalt']\n",
    "\n",
    "# Apply combined Min-Max normalization within each crime category\n",
    "df_normalized = df_pivoted_back.groupby('Crime').apply(\n",
    "    combined_min_max_normalize, columns=columns_to_normalize\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Save the normalized DataFrame to a CSV file\n",
    "df_normalized.to_csv('data_normalized.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8ec6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the columns to delete\n",
    "columns_to_delete = [\n",
    "    'Opfer insgesamt_2023',  'Nichtdeutsche insgesamt_2023',\n",
    "    'Deutsche_Opfer_norm_2023', 'Nichtdeutsche_Opfer_norm_2023',\n",
    "    'Opfer insgesamt_2022', 'Nichtdeutsche insgesamt_2022',\n",
    "    'Deutsche_Opfer_norm_2022', 'Nichtdeutsche_Opfer_norm_2022',\n",
    "    'Opfer insgesamt_2021',  'Nichtdeutsche insgesamt_2021',\n",
    "    'Deutsche_Opfer_norm_2021', 'Nichtdeutsche_Opfer_norm_2021',\n",
    "    'Opfer insgesamt_2020',  'Nichtdeutsche insgesamt_2020',\n",
    "    'Deutsche_Opfer_norm_2020', 'Nichtdeutsche_Opfer_norm_2020',\n",
    "    'Opfer insgesamt_2019',  'Nichtdeutsche insgesamt_2019',\n",
    "    'Deutsche_Opfer_norm_2019', 'Nichtdeutsche_Opfer_norm_2019'\n",
    "]\n",
    "\n",
    "# Drop the unwanted columns\n",
    "data_combined_countries = data_combined.drop(columns=columns_to_delete)\n",
    "\n",
    "data_combined_countries=data_combined_countries.reset_index(names='Crime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4094f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists of countries\n",
    "european_countries = ['Bulgarien', 'Frankreich', 'Griechenland', 'Italien', 'Rumänien', \n",
    "                      'Niederlande', 'Polen', 'Portugal', 'Rumänien', 'Spanien', \n",
    "                      'Ungarn', 'Österreich', 'Serbien']\n",
    "\n",
    "refugee_countries = ['Afghanistan', 'Irak', 'Kosovo', 'Syrien', 'Ukraine', 'Türkei']\n",
    "other_countries = ['China', 'Indien', 'Russische Föderation']\n",
    "\n",
    "# Define function to generate columns for each year\n",
    "def generate_yearly_columns(country_list, year):\n",
    "    return [f\"{country}_{year}\" for country in country_list]\n",
    "\n",
    "# Generate yearly columns\n",
    "years = [2023, 2022, 2021, 2020, 2019]\n",
    "european_columns = {year: generate_yearly_columns(european_countries, year) for year in years}\n",
    "refugee_columns = {year: generate_yearly_columns(refugee_countries, year) for year in years}\n",
    "other_columns = {year: generate_yearly_columns(other_countries, year) for year in years}\n",
    "\n",
    "# Define function to sum columns for each category and year\n",
    "def sum_columns_for_year(dataframe, columns_dict, category_name):\n",
    "    for year, columns in columns_dict.items():\n",
    "        dataframe[f'{category_name}_{year}'] = dataframe[columns].sum(axis=1)\n",
    "    return \n",
    "# Apply the function to sum columns for each category\n",
    "sum_columns_for_year(data_combined_countries, european_columns, 'Europäische Länder')\n",
    "sum_columns_for_year(data_combined_countries, refugee_columns, 'Asylsuchende')\n",
    "sum_columns_for_year(data_combined_countries, other_columns, 'Andere Länder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a099db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>3</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Deutschland_2023</th>\n",
       "      <th>Afghanistan_2023</th>\n",
       "      <th>Ägypten_2023</th>\n",
       "      <th>Albanien_2023</th>\n",
       "      <th>Algerien_2023</th>\n",
       "      <th>Andorra_2023</th>\n",
       "      <th>Angola_2023</th>\n",
       "      <th>Antigua und Barbuda_2023</th>\n",
       "      <th>Äquatorialguinea_2023</th>\n",
       "      <th>...</th>\n",
       "      <th>Asylsuchende_2023</th>\n",
       "      <th>Asylsuchende_2022</th>\n",
       "      <th>Asylsuchende_2021</th>\n",
       "      <th>Asylsuchende_2020</th>\n",
       "      <th>Asylsuchende_2019</th>\n",
       "      <th>Andere Länder_2023</th>\n",
       "      <th>Andere Länder_2022</th>\n",
       "      <th>Andere Länder_2021</th>\n",
       "      <th>Andere Länder_2020</th>\n",
       "      <th>Andere Länder_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abandonment</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arson</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assault</td>\n",
       "      <td>1126300.0</td>\n",
       "      <td>33264.0</td>\n",
       "      <td>2641.0</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>6251.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200398.0</td>\n",
       "      <td>164760</td>\n",
       "      <td>129522</td>\n",
       "      <td>142202.0</td>\n",
       "      <td>142233</td>\n",
       "      <td>13130.0</td>\n",
       "      <td>11032</td>\n",
       "      <td>9784</td>\n",
       "      <td>10817.0</td>\n",
       "      <td>10330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deprivation of Personal Liberty</td>\n",
       "      <td>886846.0</td>\n",
       "      <td>9228.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88780.0</td>\n",
       "      <td>72795</td>\n",
       "      <td>57950</td>\n",
       "      <td>53187.0</td>\n",
       "      <td>50527</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>5170</td>\n",
       "      <td>3985</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>3793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homicide</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>561.0</td>\n",
       "      <td>555</td>\n",
       "      <td>500</td>\n",
       "      <td>599.0</td>\n",
       "      <td>484</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Murder</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>246.0</td>\n",
       "      <td>194</td>\n",
       "      <td>150</td>\n",
       "      <td>200.0</td>\n",
       "      <td>264</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Resisting Arrest</td>\n",
       "      <td>200616.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>314.0</td>\n",
       "      <td>272</td>\n",
       "      <td>230</td>\n",
       "      <td>244.0</td>\n",
       "      <td>184</td>\n",
       "      <td>46.0</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Robbery</td>\n",
       "      <td>99544.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11556.0</td>\n",
       "      <td>8402</td>\n",
       "      <td>6596</td>\n",
       "      <td>7175.0</td>\n",
       "      <td>7178</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>860</td>\n",
       "      <td>630</td>\n",
       "      <td>773.0</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sex-Related Offenses</td>\n",
       "      <td>181303.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8739.0</td>\n",
       "      <td>7568</td>\n",
       "      <td>5256</td>\n",
       "      <td>5402.0</td>\n",
       "      <td>5063</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1036</td>\n",
       "      <td>774</td>\n",
       "      <td>825.0</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smuggling of Persons</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 940 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "3                            Crime  Deutschland_2023  Afghanistan_2023  \\\n",
       "0                      Abandonment              90.0               0.0   \n",
       "1                            Arson              56.0               2.0   \n",
       "2                          Assault         1126300.0           33264.0   \n",
       "3  Deprivation of Personal Liberty          886846.0            9228.0   \n",
       "4                         Homicide            2869.0              80.0   \n",
       "5                           Murder            1382.0              18.0   \n",
       "6                 Resisting Arrest          200616.0               4.0   \n",
       "7                          Robbery           99544.0            2021.0   \n",
       "8             Sex-Related Offenses          181303.0            1025.0   \n",
       "9             Smuggling of Persons               0.0               0.0   \n",
       "\n",
       "3  Ägypten_2023  Albanien_2023  Algerien_2023  Andorra_2023  Angola_2023  \\\n",
       "0           0.0            0.0            0.0           0.0          1.0   \n",
       "1           0.0            0.0            0.0           0.0          0.0   \n",
       "2        2641.0         3840.0         6251.0           4.0        433.0   \n",
       "3        1052.0         1393.0          878.0           0.0         89.0   \n",
       "4           0.0           21.0           20.0           0.0          0.0   \n",
       "5           0.0           10.0            2.0           0.0          0.0   \n",
       "6           6.0            0.0            4.0           0.0          0.0   \n",
       "7         230.0          242.0          490.0           0.0         16.0   \n",
       "8         110.0          207.0           87.0           0.0         15.0   \n",
       "9           0.0            0.0            0.0           0.0          0.0   \n",
       "\n",
       "3  Antigua und Barbuda_2023  Äquatorialguinea_2023  ...  Asylsuchende_2023  \\\n",
       "0                       0.0                    0.0  ...                5.0   \n",
       "1                       0.0                    0.0  ...               10.0   \n",
       "2                       4.0                   27.0  ...           200398.0   \n",
       "3                       0.0                   16.0  ...            88780.0   \n",
       "4                       0.0                    0.0  ...              561.0   \n",
       "5                       0.0                    2.0  ...              246.0   \n",
       "6                       0.0                    0.0  ...              314.0   \n",
       "7                       0.0                    8.0  ...            11556.0   \n",
       "8                       0.0                    0.0  ...             8739.0   \n",
       "9                       0.0                    0.0  ...                0.0   \n",
       "\n",
       "3  Asylsuchende_2022  Asylsuchende_2021  Asylsuchende_2020  Asylsuchende_2019  \\\n",
       "0                  4                 10                1.0                  6   \n",
       "1                  2                  0                2.0                  0   \n",
       "2             164760             129522           142202.0             142233   \n",
       "3              72795              57950            53187.0              50527   \n",
       "4                555                500              599.0                484   \n",
       "5                194                150              200.0                264   \n",
       "6                272                230              244.0                184   \n",
       "7               8402               6596             7175.0               7178   \n",
       "8               7568               5256             5402.0               5063   \n",
       "9                  2                  0                0.0                  0   \n",
       "\n",
       "3  Andere Länder_2023  Andere Länder_2022  Andere Länder_2021  \\\n",
       "0                 0.0                   0                   0   \n",
       "1                 0.0                   0                   0   \n",
       "2             13130.0               11032                9784   \n",
       "3              6091.0                5170                3985   \n",
       "4                45.0                  26                  33   \n",
       "5                12.0                  24                  16   \n",
       "6                46.0                  34                  28   \n",
       "7              1194.0                 860                 630   \n",
       "8              1016.0                1036                 774   \n",
       "9                 0.0                   0                   0   \n",
       "\n",
       "3  Andere Länder_2020  Andere Länder_2019  \n",
       "0                 0.0                   0  \n",
       "1                 0.0                   0  \n",
       "2             10817.0               10330  \n",
       "3              3918.0                3793  \n",
       "4                35.0                  26  \n",
       "5                18.0                  16  \n",
       "6                22.0                  14  \n",
       "7               773.0                 747  \n",
       "8               825.0                 756  \n",
       "9                 0.0                   0  \n",
       "\n",
       "[10 rows x 940 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c338a2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to fetch and parse the HTML content\n",
    "def fetch_webpage(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Function to find and parse the table into a DataFrame\n",
    "def extract_table_from_soup(soup):\n",
    "    table = soup.find('table')  # Modify this if needed to locate the specific table\n",
    "    if table:\n",
    "        df = pd.read_html(str(table))[0]\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No table found.\")\n",
    "        return None\n",
    "\n",
    "# Function to clean and filter the DataFrame\n",
    "def clean_and_filter_dataframe(df):\n",
    "    df = df.rename(columns={'Staats­angehörig­keit': 'Staatsangehörigkeit'})\n",
    "    df = df[['Staatsangehörigkeit', '2023', '2022', '2021', '2020', '2019']]\n",
    "    \n",
    "    # Correct specific country names\n",
    "    corrections = {\n",
    "        'Ukraine3': 'Ukraine',\n",
    "        'Russische\\xa0Föderation': 'Russische Föderation'\n",
    "    }\n",
    "    df['Staatsangehörigkeit'] = df['Staatsangehörigkeit'].replace(corrections)\n",
    "    \n",
    "    # Define country groups\n",
    "    all_countries = ['Rumänien', 'Polen', 'Italien', 'Bulgarien', 'Kroatien', 'Griechenland', \n",
    "                     'Ungarn', 'Spanien', 'Österreich', 'Niederlande', 'Frankreich', 'Portugal',\n",
    "                     'Türkei', 'Ukraine', 'Russische Föderation', 'Kosovo', 'Serbien',\n",
    "                     'Vereinigte Staaten (USA)', 'Syrien', 'Afghanistan', 'Irak', 'Indien', 'China']\n",
    "    \n",
    "    # Filter rows based on country\n",
    "    df = df[df['Staatsangehörigkeit'].isin(all_countries)]\n",
    "    \n",
    "    # Clean and convert data types\n",
    "    df[['2023', '2022', '2021', '2020', '2019']] = df[['2023', '2022', '2021', '2020', '2019']].replace(r'\\xa0', '', regex=True).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main process function\n",
    "def process_web_data(url):\n",
    "    soup = fetch_webpage(url)\n",
    "    if soup:\n",
    "        df = extract_table_from_soup(soup)\n",
    "        if df is not None:\n",
    "            df = clean_and_filter_dataframe(df)\n",
    "            df.to_csv('states_germany.csv', index=False)\n",
    "            print(\"Data saved successfully.\")\n",
    "        else:\n",
    "            print(\"Failed to process the DataFrame.\")\n",
    "    else:\n",
    "        print(\"Failed to fetch or parse webpage content.\")\n",
    "    return df\n",
    "# URL of the target webpage\n",
    "url = 'https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Bevoelkerung/Migration-Integration/Tabellen/auslaendische-bevoelkerung-staatsangehoerigkeit-jahre.html'\n",
    "df=process_web_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4336640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define your countries lists\n",
    "european_countries = ['Bulgarien', 'Frankreich', 'Griechenland', 'Italien', 'Rumänien', \n",
    "                      'Niederlande', 'Polen', 'Portugal', 'Rumänien', 'Spanien', \n",
    "                      'Ungarn', 'Österreich', 'Serbien']\n",
    "refugee_countries = ['Afghanistan', 'Irak', 'Kosovo', 'Syrien', 'Ukraine', 'Türkei']\n",
    "other_countries = ['China', 'Indien', 'Russische Föderation']\n",
    "\n",
    "# Function to sum values for a given group of countries\n",
    "def sum_country_data(df, countries, label):\n",
    "    df_filtered = df[df['Staatsangehörigkeit'].isin(countries)]\n",
    "    summed_values = df_filtered.drop(columns=['Staatsangehörigkeit']).sum().to_frame().T\n",
    "    summed_values['Staatsangehörigkeit'] = label\n",
    "    return summed_values\n",
    "\n",
    "# Sum values for each group and append to the DataFrame\n",
    "def append_summed_values(df, european_countries, refugee_countries, other_countries):\n",
    "    summed_european = sum_country_data(df, european_countries, 'Europäische Länder')\n",
    "    summed_refugee = sum_country_data(df, refugee_countries, 'Asylsuchende')\n",
    "    summed_other = sum_country_data(df, other_countries, 'Andere Länder')\n",
    "\n",
    "    # Concatenate summed rows with the original DataFrame\n",
    "    return pd.concat([df, summed_european, summed_refugee, summed_other], ignore_index=True)\n",
    "\n",
    "# Function to add a new row\n",
    "def add_new_row(df, new_row):\n",
    "    df.loc[len(df)] = new_row\n",
    "    return df\n",
    "\n",
    "# Assuming df is already defined\n",
    "df = append_summed_values(df, european_countries, refugee_countries, other_countries)\n",
    "\n",
    "# Add a new row for Germany\n",
    "new_row = {\n",
    "    'Staatsangehörigkeit': 'Deutschland',\n",
    "    '2023': 71855657,\n",
    "    '2022': 72034650,\n",
    "    '2021': 72344071,\n",
    "    '2020': 72569978,\n",
    "    '2019': 72768689\n",
    "}\n",
    "\n",
    "df = add_new_row(df, new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9206b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to melt the population DataFrame\n",
    "def melt_population_data(df_population):\n",
    "    return df_population.melt(id_vars=['Staatsangehörigkeit'], var_name='Year', value_name='Population')\n",
    "\n",
    "# Function to parse and extract relevant components from column names\n",
    "def parse_column_names(df, prefix=\"\"):\n",
    "    crime_cols = df.columns[1:]  # Assuming the first column is 'Crime'\n",
    "    parsed_columns = crime_cols.str.extract(r'(?P<Country>.*)_(?P<Year>\\d{4})')\n",
    "    parsed_columns['Original'] = crime_cols\n",
    "    parsed_columns['Country'] = prefix + parsed_columns['Country']  # Adding prefix if needed\n",
    "    return parsed_columns\n",
    "\n",
    "# Function to merge crime data with population data\n",
    "def merge_data(df_population, data_combined_countries, parsed_columns):\n",
    "    # Ensure 'Year' is string for accurate merging\n",
    "    df_population['Year'] = df_population['Year'].astype(str)\n",
    "    \n",
    "    # Initialize a result DataFrame\n",
    "    result_data = {'Crime': data_combined_countries['Crime'].values}\n",
    "    \n",
    "    # Iterate over each row in the parsed columns DataFrame\n",
    "    for _, row in parsed_columns.iterrows():\n",
    "        country = row['Country']\n",
    "        year = row['Year']\n",
    "        original_col = row['Original']\n",
    "        \n",
    "        # Find the matching population\n",
    "        matched_population = df_population[\n",
    "            (df_population['Staatsangehörigkeit'] == country) & (df_population['Year'] == year)\n",
    "        ]\n",
    "        \n",
    "        if not matched_population.empty:\n",
    "            population = matched_population['Population'].values[0]\n",
    "            # Calculate the crime rate per population\n",
    "            result_data[original_col] = data_combined_countries[original_col] / population\n",
    "\n",
    "    return pd.DataFrame(result_data)\n",
    "\n",
    "# Assuming df_population and data_combined_countries are predefined\n",
    "df_population_melted = melt_population_data(df)\n",
    "parsed_columns = parse_column_names(data_combined_countries)\n",
    "\n",
    "# Merge the datasets\n",
    "df_result = merge_data(df_population_melted, data_combined_countries, parsed_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abdababc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/4080438250.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  melted_df['Country'] = melted_df['Year_Variable'].str.replace(r'_\\d{4}$', '')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def melt_dataframe(df):\n",
    "    # Use pd.melt to pivot the DataFrame\n",
    "    melted_df = pd.melt(df.reset_index(), id_vars='Crime', value_vars=df.columns,\n",
    "                        var_name='Year_Variable', value_name='Value')\n",
    "\n",
    "    # Extract the year and the country from the 'Year_Variable' column\n",
    "    melted_df['Year'] = melted_df['Year_Variable'].str.extract(r'(\\d{4})$')\n",
    "    melted_df['Country'] = melted_df['Year_Variable'].str.replace(r'_\\d{4}$', '')\n",
    "\n",
    "    # Remove the 'Year_Variable' column\n",
    "    return melted_df.drop(columns=['Year_Variable'])\n",
    "\n",
    "def rearrange_and_filter(df):\n",
    "    # Rearrange the columns for better readability\n",
    "    df = df[['Crime', 'Year', 'Country', 'Value']]\n",
    "\n",
    "    # Create a pivot table with 'Year' and 'Crime' as the index and 'Country' as the columns\n",
    "    df_pivoted = df.pivot_table(index=['Year', 'Crime'], columns='Country', values='Value').reset_index()\n",
    "\n",
    "    # Filter out specific crime categories\n",
    "    excluded_crimes = {'Abandonment', 'Arson', 'Smuggling of Persons', 'Resisting Arrest'}\n",
    "    return df_pivoted[~df_pivoted['Crime'].isin(excluded_crimes)]\n",
    "\n",
    "# Assuming df_result is already defined\n",
    "df_to_pivot = df_result.copy()\n",
    "df_melted = melt_dataframe(df_to_pivot)\n",
    "\n",
    "# Save the tidy DataFrame to a CSV file\n",
    "df_melted.to_csv('tidy_crime_data.csv', index=False)\n",
    "\n",
    "df_pivoted_back_ = rearrange_and_filter(df_melted)\n",
    "df_pivoted_back_.to_csv('pivot_crime_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5950c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/sgj3q0zj6xvcgvl5h1k6w_nm0000gn/T/ipykernel_79233/1282352720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sum['Crime'] = f'{crime1}-{crime2}'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def merge_and_sum_crimes(df, crime1, crime2, suffixes=('_Homicide', '_Murder')):\n",
    "    # Filter DataFrames for specified crimes\n",
    "    df_crime1 = df[df['Crime'] == crime1]\n",
    "    df_crime2 = df[df['Crime'] == crime2]\n",
    "    \n",
    "    # Merge the two dataframes on 'Year' and 'Crime'\n",
    "    df_merged = pd.merge(df_crime1, df_crime2, on=['Year'], suffixes=suffixes)\n",
    "\n",
    "    # Define the countries and regions for which to sum values\n",
    "    countries = ['Deutschland', 'Afghanistan', 'Bulgarien', 'China', 'Frankreich',\n",
    "                 'Griechenland', 'Indien', 'Irak', 'Italien', 'Kosovo', 'Kroatien',\n",
    "                 'Niederlande', 'Polen', 'Portugal', 'Rumänien', 'Russische Föderation',\n",
    "                 'Serbien', 'Spanien', 'Syrien', 'Türkei', 'Ukraine', 'Ungarn',\n",
    "                 'Österreich', 'Europäische Länder', 'Asylsuchende', 'Andere Länder']\n",
    "    \n",
    "    # Sum the values for Homicide and Murder across specified columns\n",
    "    for country in countries:\n",
    "        df_merged[country] = df_merged[f'{country}{suffixes[0]}'] + df_merged[f'{country}{suffixes[1]}']\n",
    "        df_merged = df_merged.drop(columns=[f'{country}{suffixes[0]}', f'{country}{suffixes[1]}'])\n",
    "\n",
    "    # Select relevant columns and set the Crime column\n",
    "    df_sum = df_merged[['Year'] + countries]\n",
    "    df_sum['Crime'] = f'{crime1}-{crime2}'\n",
    "\n",
    "    return df_sum\n",
    "\n",
    "# Assuming df_pivoted_back_ is predefined\n",
    "# Merge and sum data for 'Homicide' and 'Murder'\n",
    "df_sum = merge_and_sum_crimes(df_pivoted_back_, 'Homicide', 'Murder')\n",
    "\n",
    "# Filter out the original 'Homicide' and 'Murder' rows and append the new summed data\n",
    "df_pivoted_back_ = df_pivoted_back_[(df_pivoted_back_['Crime'] != 'Homicide') & (df_pivoted_back_['Crime'] != 'Murder')]\n",
    "df_pivoted_back_ = pd.concat([df_pivoted_back_, df_sum], ignore_index=True)\n",
    "\n",
    "# Optionally, save the final DataFrame to CSV\n",
    "df_pivoted_back_.to_csv('final_crime_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b17692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the original lists aren't modified by creating new lists that include the additional fields\n",
    "def update_country_list(original_list, extra_fields):\n",
    "    return original_list + extra_fields\n",
    "\n",
    "# Define additional fields\n",
    "additional_fields = ['Year', 'Crime', 'Deutschland']\n",
    "\n",
    "# Update lists with additional fields for CSV output\n",
    "european_countries_extended = update_country_list(european_countries, additional_fields + ['Europäische Länder'])\n",
    "refugee_countries_extended = update_country_list(refugee_countries, additional_fields + ['Asylsuchende'])\n",
    "other_countries_extended = update_country_list(other_countries, additional_fields + ['Andere Länder'])\n",
    "df_extended = pd.concat([df_pivoted_back_, df_sum], ignore_index=True)\n",
    "\n",
    "# Assuming df_extended is already defined and correctly concatenated\n",
    "df_extended.to_csv('states_germany_crimes.csv', index=False)\n",
    "\n",
    "# Export specific subsets of the data to separate CSV files\n",
    "df_extended[european_countries_extended].to_csv('EU_states_germany_crimes.csv', index=False)\n",
    "df_extended[refugee_countries_extended].to_csv('asyl_states_germany_crimes.csv', index=False)\n",
    "df_extended[other_countries_extended].to_csv('other_states_german_crimes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31683cca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
